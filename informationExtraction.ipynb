{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load base packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# load utalities\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "# load dataset tools\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "# preprocessing tools\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# load models\n",
    "\n",
    "\n",
    "# load eval tools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# load tokenizing tools\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract handout.txt from each subdirectory of RawData\n",
    "def read_handout_txt():\n",
    "    data = []\n",
    "\n",
    "    for root, dirs, files in os.walk(\"./data/RawData/\"):\n",
    "        try:\n",
    "            with open(os.path.join(root, \"handout.txt\"), \"r\") as f:\n",
    "                handout = f.readlines()\n",
    "        except:\n",
    "            print(f\"{root}/handout.txt Not Found\")\n",
    "            continue\n",
    "\n",
    "        for i, line in enumerate(handout):\n",
    "            line = line.strip()\n",
    "\n",
    "            # number lines\n",
    "            line_dict = {\n",
    "                \"Drug name\": root.split(\"/\")[-1],\n",
    "                \"Line number\": i + 1,\n",
    "                \"Line\": line,\n",
    "            }\n",
    "\n",
    "            data.append(line_dict)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_df = pd.read_csv(\"data/AnnotatedData/AnnotatedDUGData.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/RawData//handout.txt Not Found\n",
      "./data/RawData/Coreg/handout.txt Not Found\n"
     ]
    }
   ],
   "source": [
    "raw_df = pd.DataFrame(read_handout_txt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Drug name</th>\n",
       "      <th>Line number</th>\n",
       "      <th>Line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abilify</td>\n",
       "      <td>1</td>\n",
       "      <td>Patient Educationaripiprazole intramuscular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abilify</td>\n",
       "      <td>2</td>\n",
       "      <td>IMPORTANT: HOW TO USE THIS INFORMATION:  This ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abilify</td>\n",
       "      <td>3</td>\n",
       "      <td>ARIPIPRAZOLE EXTENDED RELEASE - INJECTION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abilify</td>\n",
       "      <td>4</td>\n",
       "      <td>(AR-i-PIP-ra-zole)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abilify</td>\n",
       "      <td>5</td>\n",
       "      <td>COMMON BRAND NAME(S): Abilify Maintena, Aristada</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Drug name  Line number                                               Line\n",
       "0   Abilify            1        Patient Educationaripiprazole intramuscular\n",
       "1   Abilify            2  IMPORTANT: HOW TO USE THIS INFORMATION:  This ...\n",
       "2   Abilify            3          ARIPIPRAZOLE EXTENDED RELEASE - INJECTION\n",
       "3   Abilify            4                                 (AR-i-PIP-ra-zole)\n",
       "4   Abilify            5   COMMON BRAND NAME(S): Abilify Maintena, Aristada"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Drug name</th>\n",
       "      <th>Drug number</th>\n",
       "      <th>Advice Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abilify</td>\n",
       "      <td>0</td>\n",
       "      <td>To reduce the risk of dizziness and lightheade...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abilify</td>\n",
       "      <td>0</td>\n",
       "      <td>This medication may rarely make your blood sug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abilify</td>\n",
       "      <td>0</td>\n",
       "      <td>This medication may rarely cause a condition k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abilify</td>\n",
       "      <td>0</td>\n",
       "      <td>This drug may make you dizzy or drowsy or caus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abilify</td>\n",
       "      <td>0</td>\n",
       "      <td>Avoid alcoholic beverages.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Drug name  Drug number                                        Advice Text\n",
       "0   Abilify            0  To reduce the risk of dizziness and lightheade...\n",
       "1   Abilify            0  This medication may rarely make your blood sug...\n",
       "2   Abilify            0  This medication may rarely cause a condition k...\n",
       "3   Abilify            0  This drug may make you dizzy or drowsy or caus...\n",
       "4   Abilify            0                         Avoid alcoholic beverages."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anno_df = anno_df[[\"Drug name\", \"Drug number\", \"Advice Text\"]]\n",
    "anno_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reassign line numbers\n",
    "\n",
    "The line number present in the data is determined based off of scentence structure and not line number. We will locate the Advice text in the raw text, and assign it a new line number label based on the corresponing line. \n",
    "\n",
    "This will help us to assign IOB tags to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_line_number(advice, raw_data_df):\n",
    "\n",
    "    for i, line in raw_data_df.iterrows():\n",
    "        if advice in line[\"Line\"]:\n",
    "            return line[\"Line number\"]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Drug name</th>\n",
       "      <th>Drug number</th>\n",
       "      <th>Advice Text</th>\n",
       "      <th>Line number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abilify</td>\n",
       "      <td>0</td>\n",
       "      <td>To reduce the risk of dizziness and lightheade...</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abilify</td>\n",
       "      <td>0</td>\n",
       "      <td>This medication may rarely make your blood sug...</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abilify</td>\n",
       "      <td>0</td>\n",
       "      <td>This medication may rarely cause a condition k...</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abilify</td>\n",
       "      <td>0</td>\n",
       "      <td>This drug may make you dizzy or drowsy or caus...</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abilify</td>\n",
       "      <td>0</td>\n",
       "      <td>Avoid alcoholic beverages.</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Drug name  Drug number                                        Advice Text  \\\n",
       "0   Abilify            0  To reduce the risk of dizziness and lightheade...   \n",
       "1   Abilify            0  This medication may rarely make your blood sug...   \n",
       "2   Abilify            0  This medication may rarely cause a condition k...   \n",
       "3   Abilify            0  This drug may make you dizzy or drowsy or caus...   \n",
       "4   Abilify            0                         Avoid alcoholic beverages.   \n",
       "\n",
       "   Line number  \n",
       "0         17.0  \n",
       "1         20.0  \n",
       "2         21.0  \n",
       "3         31.0  \n",
       "4         31.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find line number for each advice text\n",
    "anno_df[\"Line number\"] = anno_df[\"Advice Text\"].apply(\n",
    "    lambda x: find_line_number(x, raw_df)\n",
    ")\n",
    "anno_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Drug name</th>\n",
       "      <th>Drug number</th>\n",
       "      <th>Advice Text</th>\n",
       "      <th>Line number</th>\n",
       "      <th>Line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abilify</td>\n",
       "      <td>0</td>\n",
       "      <td>To reduce the risk of dizziness and lightheade...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>To reduce the risk of dizziness and lightheade...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abilify</td>\n",
       "      <td>0</td>\n",
       "      <td>This medication may rarely make your blood sug...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>This medication may rarely make your blood sug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abilify</td>\n",
       "      <td>0</td>\n",
       "      <td>This medication may rarely cause a condition k...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>This medication may rarely cause a condition k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abilify</td>\n",
       "      <td>0</td>\n",
       "      <td>This drug may make you dizzy or drowsy or caus...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>This drug may make you dizzy or drowsy or caus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abilify</td>\n",
       "      <td>0</td>\n",
       "      <td>Avoid alcoholic beverages.</td>\n",
       "      <td>31.0</td>\n",
       "      <td>This drug may make you dizzy or drowsy or caus...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Drug name  Drug number                                        Advice Text  \\\n",
       "0   Abilify            0  To reduce the risk of dizziness and lightheade...   \n",
       "1   Abilify            0  This medication may rarely make your blood sug...   \n",
       "2   Abilify            0  This medication may rarely cause a condition k...   \n",
       "3   Abilify            0  This drug may make you dizzy or drowsy or caus...   \n",
       "4   Abilify            0                         Avoid alcoholic beverages.   \n",
       "\n",
       "   Line number                                               Line  \n",
       "0         17.0  To reduce the risk of dizziness and lightheade...  \n",
       "1         20.0  This medication may rarely make your blood sug...  \n",
       "2         21.0  This medication may rarely cause a condition k...  \n",
       "3         31.0  This drug may make you dizzy or drowsy or caus...  \n",
       "4         31.0  This drug may make you dizzy or drowsy or caus...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge dataframes\n",
    "merged_df = pd.merge(anno_df, raw_df, on=[\"Drug name\", \"Line number\"])\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IOB tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the advice text vs line text to create iob tagging\n",
    "def tag_iob(line, advice):\n",
    "\n",
    "    # basic tokenization\n",
    "    line_tokens = re.sub(r\"[^\\w\\s]\", \"\", line).split()\n",
    "    advice_tokens = re.sub(r\"[^\\w\\s]\", \"\", advice).split()\n",
    "\n",
    "    tagged_tokens = []\n",
    "    for i, word in enumerate(line_tokens):\n",
    "        tag = \"O\"\n",
    "        if word in advice_tokens:\n",
    "            tag = \"B\" if word == advice_tokens[0] else \"I\"\n",
    "            tag = \"E\" if word == advice_tokens[-1] else tag\n",
    "\n",
    "        tagged_tokens.append((word, tag))\n",
    "        if tag == \"E\":\n",
    "            break\n",
    "\n",
    "    for word in line_tokens[i + 1 :]:\n",
    "        tagged_tokens.append((word, \"O\"))\n",
    "    return tagged_tokens\n",
    "\n",
    "\n",
    "# NOTE: This function will have issues if the last word of the advice\n",
    "# text also appears in the line text not as the last word\n",
    "# needs to be fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Drug name</th>\n",
       "      <th>Drug number</th>\n",
       "      <th>Advice Text</th>\n",
       "      <th>Line number</th>\n",
       "      <th>Line</th>\n",
       "      <th>IOB Tagged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abilify</td>\n",
       "      <td>0</td>\n",
       "      <td>To reduce the risk of dizziness and lightheade...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>To reduce the risk of dizziness and lightheade...</td>\n",
       "      <td>[(To, B), (reduce, I), (the, I), (risk, I), (o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abilify</td>\n",
       "      <td>0</td>\n",
       "      <td>This medication may rarely make your blood sug...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>This medication may rarely make your blood sug...</td>\n",
       "      <td>[(This, B), (medication, I), (may, I), (rarely...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abilify</td>\n",
       "      <td>0</td>\n",
       "      <td>This medication may rarely cause a condition k...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>This medication may rarely cause a condition k...</td>\n",
       "      <td>[(This, B), (medication, I), (may, I), (rarely...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abilify</td>\n",
       "      <td>0</td>\n",
       "      <td>This drug may make you dizzy or drowsy or caus...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>This drug may make you dizzy or drowsy or caus...</td>\n",
       "      <td>[(This, B), (drug, I), (may, I), (make, I), (y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abilify</td>\n",
       "      <td>0</td>\n",
       "      <td>Avoid alcoholic beverages.</td>\n",
       "      <td>31.0</td>\n",
       "      <td>This drug may make you dizzy or drowsy or caus...</td>\n",
       "      <td>[(This, O), (drug, O), (may, O), (make, O), (y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Drug name  Drug number                                        Advice Text  \\\n",
       "0   Abilify            0  To reduce the risk of dizziness and lightheade...   \n",
       "1   Abilify            0  This medication may rarely make your blood sug...   \n",
       "2   Abilify            0  This medication may rarely cause a condition k...   \n",
       "3   Abilify            0  This drug may make you dizzy or drowsy or caus...   \n",
       "4   Abilify            0                         Avoid alcoholic beverages.   \n",
       "\n",
       "   Line number                                               Line  \\\n",
       "0         17.0  To reduce the risk of dizziness and lightheade...   \n",
       "1         20.0  This medication may rarely make your blood sug...   \n",
       "2         21.0  This medication may rarely cause a condition k...   \n",
       "3         31.0  This drug may make you dizzy or drowsy or caus...   \n",
       "4         31.0  This drug may make you dizzy or drowsy or caus...   \n",
       "\n",
       "                                          IOB Tagged  \n",
       "0  [(To, B), (reduce, I), (the, I), (risk, I), (o...  \n",
       "1  [(This, B), (medication, I), (may, I), (rarely...  \n",
       "2  [(This, B), (medication, I), (may, I), (rarely...  \n",
       "3  [(This, B), (drug, I), (may, I), (make, I), (y...  \n",
       "4  [(This, O), (drug, O), (may, O), (make, O), (y...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_df = merged_df.copy()\n",
    "tagged_df[\"IOB Tagged\"] = tagged_df.apply(\n",
    "    lambda x: tag_iob(x[\"Line\"], x[\"Advice Text\"]), axis=1\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "tagged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('This', 'B'),\n",
       " ('medication', 'I'),\n",
       " ('may', 'I'),\n",
       " ('rarely', 'I'),\n",
       " ('make', 'I'),\n",
       " ('your', 'I'),\n",
       " ('blood', 'I'),\n",
       " ('sugar', 'I'),\n",
       " ('level', 'I'),\n",
       " ('rise', 'I'),\n",
       " ('which', 'I'),\n",
       " ('can', 'I'),\n",
       " ('cause', 'I'),\n",
       " ('or', 'I'),\n",
       " ('worsen', 'I'),\n",
       " ('diabetes', 'I'),\n",
       " ('Rarely', 'I'),\n",
       " ('very', 'I'),\n",
       " ('serious', 'I'),\n",
       " ('conditions', 'I'),\n",
       " ('such', 'I'),\n",
       " ('as', 'I'),\n",
       " ('diabetic', 'I'),\n",
       " ('coma', 'I'),\n",
       " ('may', 'I'),\n",
       " ('occur', 'I'),\n",
       " ('Tell', 'I'),\n",
       " ('your', 'I'),\n",
       " ('doctor', 'I'),\n",
       " ('right', 'I'),\n",
       " ('away', 'I'),\n",
       " ('if', 'I'),\n",
       " ('you', 'I'),\n",
       " ('develop', 'I'),\n",
       " ('symptoms', 'I'),\n",
       " ('of', 'I'),\n",
       " ('high', 'I'),\n",
       " ('blood', 'I'),\n",
       " ('sugar', 'I'),\n",
       " ('such', 'I'),\n",
       " ('as', 'I'),\n",
       " ('increased', 'I'),\n",
       " ('thirst', 'I'),\n",
       " ('and', 'I'),\n",
       " ('urination', 'I'),\n",
       " ('If', 'I'),\n",
       " ('you', 'I'),\n",
       " ('already', 'I'),\n",
       " ('have', 'I'),\n",
       " ('diabetes', 'I'),\n",
       " ('be', 'I'),\n",
       " ('sure', 'I'),\n",
       " ('to', 'I'),\n",
       " ('check', 'I'),\n",
       " ('your', 'I'),\n",
       " ('blood', 'I'),\n",
       " ('sugars', 'I'),\n",
       " ('regularly', 'E'),\n",
       " ('Your', 'O'),\n",
       " ('doctor', 'O'),\n",
       " ('may', 'O'),\n",
       " ('need', 'O'),\n",
       " ('to', 'O'),\n",
       " ('adjust', 'O'),\n",
       " ('your', 'O'),\n",
       " ('diabetes', 'O'),\n",
       " ('medication', 'O'),\n",
       " ('exercise', 'O'),\n",
       " ('program', 'O'),\n",
       " ('or', 'O'),\n",
       " ('diet', 'O')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the first IOB taged text\n",
    "tagged_df[\"IOB Tagged\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This medication may rarely make your blood sugar level rise, which can cause or worsen diabetes. Rarely, very serious conditions such as diabetic coma may occur. Tell your doctor right away if you develop symptoms of high blood sugar, such as increased thirst and urination. If you already have diabetes, be sure to check your blood sugars regularly.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the first Advice Text\n",
    "tagged_df[\"Advice Text\"][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert tagged data to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[To, reduce, the, risk, of, dizziness, and, li...</td>\n",
       "      <td>[B, I, I, I, I, I, I, I, I, I, I, I, I, I, I, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[This, medication, may, rarely, make, your, bl...</td>\n",
       "      <td>[B, I, I, I, I, I, I, I, I, I, I, I, I, I, I, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[This, medication, may, rarely, cause, a, cond...</td>\n",
       "      <td>[B, I, I, I, I, I, I, I, I, I, E, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[This, drug, may, make, you, dizzy, or, drowsy...</td>\n",
       "      <td>[B, I, I, I, I, I, I, I, I, I, I, I, I, I, I, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[This, drug, may, make, you, dizzy, or, drowsy...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  [To, reduce, the, risk, of, dizziness, and, li...   \n",
       "1  [This, medication, may, rarely, make, your, bl...   \n",
       "2  [This, medication, may, rarely, cause, a, cond...   \n",
       "3  [This, drug, may, make, you, dizzy, or, drowsy...   \n",
       "4  [This, drug, may, make, you, dizzy, or, drowsy...   \n",
       "\n",
       "                                                 tag  \n",
       "0  [B, I, I, I, I, I, I, I, I, I, I, I, I, I, I, ...  \n",
       "1  [B, I, I, I, I, I, I, I, I, I, I, I, I, I, I, ...  \n",
       "2  [B, I, I, I, I, I, I, I, I, I, E, O, O, O, O, ...  \n",
       "3  [B, I, I, I, I, I, I, I, I, I, I, I, I, I, I, ...  \n",
       "4  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe of input text and IOBE tags\n",
    "data = pd.DataFrame()\n",
    "data[\"text\"] = tagged_df[\"IOB Tagged\"].apply(lambda x: [i[0] for i in x])\n",
    "data[\"tag\"] = tagged_df[\"IOB Tagged\"].apply(lambda x: [i[1] for i in x])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[To, reduce, the, risk, of, dizziness, and, li...</td>\n",
       "      <td>[1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[This, medication, may, rarely, make, your, bl...</td>\n",
       "      <td>[1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[This, medication, may, rarely, cause, a, cond...</td>\n",
       "      <td>[1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[This, drug, may, make, you, dizzy, or, drowsy...</td>\n",
       "      <td>[1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[This, drug, may, make, you, dizzy, or, drowsy...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  [To, reduce, the, risk, of, dizziness, and, li...   \n",
       "1  [This, medication, may, rarely, make, your, bl...   \n",
       "2  [This, medication, may, rarely, cause, a, cond...   \n",
       "3  [This, drug, may, make, you, dizzy, or, drowsy...   \n",
       "4  [This, drug, may, make, you, dizzy, or, drowsy...   \n",
       "\n",
       "                                                 tag  \n",
       "0  [1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...  \n",
       "1  [1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...  \n",
       "2  [1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 0, 0, 0, 0, ...  \n",
       "3  [1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode tags\n",
    "mapping = {\"O\": 0, \"B\": 1, \"I\": 2, \"E\": 3}\n",
    "\n",
    "data[\"tag\"] = data[\"tag\"].apply(lambda x: [mapping[i] for i in x])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_random_IOB(text):\n",
    "\n",
    "    # get the length of the text\n",
    "    length = len(text)\n",
    "\n",
    "    # make array of zeros\n",
    "    preds = np.zeros(length)\n",
    "\n",
    "    # get a random number between 0 and the length of the text\n",
    "    random_start = np.random.randint(0, length - 1)\n",
    "    random_stop = np.random.randint(random_start + 1, length)\n",
    "\n",
    "    # set the random start to 1\n",
    "    preds[random_start] = 1\n",
    "\n",
    "    # set the random stop to 3\n",
    "    preds[random_stop] = 3\n",
    "\n",
    "    # set the values in between to 2\n",
    "    preds[random_start + 1 : random_stop] = 2\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "1    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "2    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "3    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "4    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = data[\"text\"].apply(pred_random_IOB)\n",
    "preds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evalute the baseline at token level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will find the accuracy for evaluating the baseline at the token level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5084916341678198"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_accuracy(ground_truth, preds):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for true, pred in zip(ground_truth, preds):\n",
    "        for t, p in zip(true, pred):\n",
    "            if t == p:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "# calculate the accuracy of the token level predictions\n",
    "calculate_accuracy(data[\"tag\"], preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the baseline at span-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tags_to_spans(tags):\n",
    "    spans = defaultdict(list)\n",
    "    current_span = None\n",
    "    for i, tag in enumerate(tags):\n",
    "        if tag == 0:  # Outside\n",
    "            current_span = None\n",
    "        elif tag == 1:  # Beginning\n",
    "            current_span = [i]\n",
    "        elif tag == 2:  # Inside\n",
    "            if current_span is not None:\n",
    "                current_span.append(i)\n",
    "        elif tag == 3:  # End\n",
    "            if current_span is not None:\n",
    "                current_span.append(i)\n",
    "                spans[current_span[0]].append(\n",
    "                    current_span[1] + 1\n",
    "                )  # Increment the end index\n",
    "                current_span = None\n",
    "    return spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_span_level(preds, ground_truth):\n",
    "    # Flatten the spans\n",
    "    flat_predictions = [span for spans in preds for span in spans]\n",
    "    flat_ground_truth = [span for spans in ground_truth for span in spans]\n",
    "\n",
    "    # Compute precision, recall, and F1-score\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(\n",
    "        flat_ground_truth, flat_predictions, average=\"macro\"\n",
    "    )\n",
    "\n",
    "    return precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Span-level precision: 0.25910493558323733\n",
      "Span-level recall: 0.2616386113657438\n",
      "Span-level F1-score: 0.2530667806679219\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1_score = evaluate_span_level(preds, data[\"tag\"])\n",
    "print(\"Span-level precision:\", precision)\n",
    "print(\"Span-level recall:\", recall)\n",
    "print(\"Span-level F1-score:\", f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"roberta-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.2, random_state=42)\n",
    "train, val = train_test_split(train, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(example, max_length=512):\n",
    "    # Because of the way that the BIOE tagging was setup, we need to make sure that the\n",
    "    # tokenization is aligned with the tagging. This means that we need to tokenize the\n",
    "    # text and then assign the correct label to each token.\n",
    "\n",
    "    text = example[\"text\"]\n",
    "    tags = example[\"tag\"]\n",
    "\n",
    "    token_ids = [tokenizer.cls_token_id]\n",
    "    label_alignment = [0]\n",
    "    attention_mask = [1]\n",
    "    special_label_for_subwords = -100\n",
    "\n",
    "    for word, label in zip(text, tags):\n",
    "        subword_tokens = tokenizer.tokenize(word)\n",
    "\n",
    "        if len(subword_tokens) > 0:\n",
    "            token_ids.extend(tokenizer.convert_tokens_to_ids(subword_tokens))\n",
    "            # Assign the correct label to the first subword token\n",
    "            label_alignment.append(label)\n",
    "            # Use a special label for subsequent subword tokens\n",
    "            label_alignment.extend(\n",
    "                [special_label_for_subwords] * (len(subword_tokens) - 1)\n",
    "            )\n",
    "            attention_mask.extend([1] * len(subword_tokens))\n",
    "\n",
    "    # add [SEP] token\n",
    "    token_ids.append(tokenizer.sep_token_id)\n",
    "    label_alignment.append(0)\n",
    "    attention_mask.append(1)\n",
    "\n",
    "    # pad to max length\n",
    "    padding_length = max_length - len(token_ids)\n",
    "    token_ids.extend([tokenizer.pad_token_id] * padding_length)\n",
    "    label_alignment.extend([0] * padding_length)\n",
    "    attention_mask.extend([0] * padding_length)\n",
    "\n",
    "    # Make sure everything has correct length\n",
    "    assert len(token_ids) == max_length\n",
    "    assert len(label_alignment) == max_length\n",
    "    assert len(attention_mask) == max_length\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": token_ids,\n",
    "        \"labels\": label_alignment,\n",
    "        \"attention_mask\": attention_mask,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.Dataset.from_pandas(train)\n",
    "val_dataset = datasets.Dataset.from_pandas(val)\n",
    "test_dataset = datasets.Dataset.from_pandas(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bee33d3a44344b6fa9bc046a24bdbca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/508 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8e3a7aec6b84643aa518028a82f86bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "301c4026a6ba4ab48c5766c1b9e18e50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/182 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(preprocess_text)\n",
    "val_dataset = val_dataset.map(preprocess_text)\n",
    "test_dataset = test_dataset.map(preprocess_text)\n",
    "\n",
    "train_dataset.set_format(\n",
    "    type=\"torch\", columns=[\"input_ids\", \"labels\", \"attention_mask\"]\n",
    ")\n",
    "val_dataset.set_format(\n",
    "    type=\"torch\", columns=[\"input_ids\", \"labels\", \"attention_mask\"]\n",
    ")\n",
    "test_dataset.set_format(\n",
    "    type=\"torch\", columns=[\"input_ids\", \"labels\", \"attention_mask\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([    0,  6323, 33119, 11990,   154, 48205,  6025, 17304, 40919, 16625,\n",
       "         22776, 28250,   368,   605,   994,   225, 16625, 12690, 37694,  2407,\n",
       "         35438, 16625,  3792,  4526, 25058, 12196, 33119,  6968,  1322, 10928,\n",
       "           463,  4970,  9178,   560,  3698, 35369, 22725,   352, 20345,   438,\n",
       "          4894,   463, 33912, 33119,   417,  5810,  5526,    29,   368, 42219,\n",
       "         43452, 16918,   281,  1452,   658,  1001,   506,  4734,  1115, 31726,\n",
       "           225,     2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1]),\n",
       " 'labels': tensor([   0,    1,    2,    2,    2, -100,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2, -100, -100,    2,    2,    2, -100,    2,    2,    2, -100,\n",
       "         -100,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2, -100,    2,    2, -100, -100, -100,    2,    2, -100,    2, -100,\n",
       "            2,    2, -100,    2,    2,    3, -100, -100, -100, -100, -100, -100,\n",
       "         -100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at first example input_ids and labels\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training arguments\n",
    "from transformers import (\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    AutoModelForTokenClassification,\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_steps=100,\n",
    "    save_total_limit=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(model_id, num_labels=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Matt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\accelerate\\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmattcalc\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Matt\\Documents\\GitHub\\630_final\\wandb\\run-20240422_000251-o7ci1bxi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mattcalc/huggingface/runs/o7ci1bxi' target=\"_blank\">stellar-pyramid-50</a></strong> to <a href='https://wandb.ai/mattcalc/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mattcalc/huggingface' target=\"_blank\">https://wandb.ai/mattcalc/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mattcalc/huggingface/runs/o7ci1bxi' target=\"_blank\">https://wandb.ai/mattcalc/huggingface/runs/o7ci1bxi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87eb90e71ba245889682de2d65715b5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2946, 'grad_norm': 12.73617935180664, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.16}\n",
      "{'loss': 1.1761, 'grad_norm': 12.37436294555664, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.31}\n",
      "{'loss': 0.8335, 'grad_norm': 18.499210357666016, 'learning_rate': 3e-06, 'epoch': 0.47}\n",
      "{'loss': 0.3163, 'grad_norm': 2.6592495441436768, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.62}\n",
      "{'loss': 0.1446, 'grad_norm': 4.017032623291016, 'learning_rate': 5e-06, 'epoch': 0.78}\n",
      "{'loss': 0.1147, 'grad_norm': 0.8436582088470459, 'learning_rate': 6e-06, 'epoch': 0.94}\n",
      "{'loss': 0.0789, 'grad_norm': 0.3250788450241089, 'learning_rate': 7.000000000000001e-06, 'epoch': 1.09}\n",
      "{'loss': 0.0809, 'grad_norm': 0.3070162534713745, 'learning_rate': 8.000000000000001e-06, 'epoch': 1.25}\n",
      "{'loss': 0.0896, 'grad_norm': 0.9073410034179688, 'learning_rate': 9e-06, 'epoch': 1.41}\n",
      "{'loss': 0.0706, 'grad_norm': 1.0010526180267334, 'learning_rate': 1e-05, 'epoch': 1.56}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c2d5c2f7ae746549c61bf6069797838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07211222499608994, 'eval_runtime': 15.079, 'eval_samples_per_second': 14.524, 'eval_steps_per_second': 1.857, 'epoch': 1.56}\n",
      "{'loss': 0.07, 'grad_norm': 0.6755059957504272, 'learning_rate': 1.1000000000000001e-05, 'epoch': 1.72}\n",
      "{'loss': 0.0701, 'grad_norm': 1.4353053569793701, 'learning_rate': 1.2e-05, 'epoch': 1.88}\n",
      "{'loss': 0.0709, 'grad_norm': 0.8421601057052612, 'learning_rate': 1.3000000000000001e-05, 'epoch': 2.03}\n",
      "{'loss': 0.0703, 'grad_norm': 0.39515814185142517, 'learning_rate': 1.4000000000000001e-05, 'epoch': 2.19}\n",
      "{'loss': 0.0701, 'grad_norm': 2.3534131050109863, 'learning_rate': 1.5e-05, 'epoch': 2.34}\n",
      "{'loss': 0.0653, 'grad_norm': 0.6852309703826904, 'learning_rate': 1.6000000000000003e-05, 'epoch': 2.5}\n",
      "{'loss': 0.0665, 'grad_norm': 0.32582950592041016, 'learning_rate': 1.7000000000000003e-05, 'epoch': 2.66}\n",
      "{'loss': 0.0732, 'grad_norm': 1.0403127670288086, 'learning_rate': 1.8e-05, 'epoch': 2.81}\n",
      "{'loss': 0.0687, 'grad_norm': 0.45743808150291443, 'learning_rate': 1.9e-05, 'epoch': 2.97}\n",
      "{'train_runtime': 245.6846, 'train_samples_per_second': 6.203, 'train_steps_per_second': 0.781, 'train_loss': 0.2520588703919202, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=192, training_loss=0.2520588703919202, metrics={'train_runtime': 245.6846, 'train_samples_per_second': 6.203, 'train_steps_per_second': 0.781, 'train_loss': 0.2520588703919202, 'epoch': 3.0})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
