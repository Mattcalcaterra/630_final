Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
c:\Users\Matt\AppData\Local\Programs\Python\Python310\lib\site-packages\accelerate\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead:
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
Random Precision: 0.20141948115516398, Recall: 0.5108628181253879, F1: 0.28892399508513256
Precision: 0.9253731343283582, Recall: 0.9253731343283582, F1: 0.9253731343283582
Precision: 0.900497512437811, Recall: 0.900497512437811, F1: 0.9004975124378111
Precision: 0.8208955223880597, Recall: 0.8208955223880597, F1: 0.8208955223880597
Precision: 0.9701492537313433, Recall: 0.9701492537313433, F1: 0.9701492537313433
Precision: 0.9154228855721394, Recall: 0.9154228855721394, F1: 0.9154228855721394
Precision: 0.8955223880597015, Recall: 0.8955223880597015, F1: 0.8955223880597015
Precision: 0.9203980099502488, Recall: 0.9203980099502488, F1: 0.9203980099502488
Precision: 0.9651741293532339, Recall: 0.9651741293532339, F1: 0.9651741293532339
Overall Precision: 0.8918918918918919, Recall: 0.6346153846153846, F1: 0.7415730337078652
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
c:\Users\Matt\AppData\Local\Programs\Python\Python310\lib\site-packages\accelerate\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead:
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
Random Precision: 0.20141948115516398, Recall: 0.5108628181253879, F1: 0.28892399508513256
Precision: 0.9253731343283582, Recall: 0.9253731343283582, F1: 0.9253731343283582
Precision: 0.900497512437811, Recall: 0.900497512437811, F1: 0.9004975124378111
Precision: 0.8208955223880597, Recall: 0.8208955223880597, F1: 0.8208955223880597
Precision: 0.9701492537313433, Recall: 0.9701492537313433, F1: 0.9701492537313433
Precision: 0.9154228855721394, Recall: 0.9154228855721394, F1: 0.9154228855721394
Precision: 0.8955223880597015, Recall: 0.8955223880597015, F1: 0.8955223880597015
Precision: 0.9203980099502488, Recall: 0.9203980099502488, F1: 0.9203980099502488
Precision: 0.9651741293532339, Recall: 0.9651741293532339, F1: 0.9651741293532339
Overall Precision: 0.8918918918918919, Recall: 0.6346153846153846, F1: 0.7415730337078652
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
c:\Users\Matt\AppData\Local\Programs\Python\Python310\lib\site-packages\accelerate\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead:
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
Random Precision: 0.20141948115516398, Recall: 0.5108628181253879, F1: 0.28892399508513256
Precision: 0.9253731343283582, Recall: 0.9253731343283582, F1: 0.9253731343283582
Precision: 0.900497512437811, Recall: 0.900497512437811, F1: 0.9004975124378111
Precision: 0.8208955223880597, Recall: 0.8208955223880597, F1: 0.8208955223880597
Precision: 0.9701492537313433, Recall: 0.9701492537313433, F1: 0.9701492537313433
Precision: 0.9154228855721394, Recall: 0.9154228855721394, F1: 0.9154228855721394
Precision: 0.8955223880597015, Recall: 0.8955223880597015, F1: 0.8955223880597015
Precision: 0.9203980099502488, Recall: 0.9203980099502488, F1: 0.9203980099502488
Precision: 0.9651741293532339, Recall: 0.9651741293532339, F1: 0.9651741293532339
Overall Precision: 0.8918918918918919, Recall: 0.6346153846153846, F1: 0.7415730337078652
Random Precision: 0.1979882237487733, Recall: 0.5009310986964618, F1: 0.28380516968524705
Precision: 0.9253731343283582, Recall: 0.9253731343283582, F1: 0.9253731343283582
Precision: 0.900497512437811, Recall: 0.900497512437811, F1: 0.9004975124378111
Precision: 0.8208955223880597, Recall: 0.8208955223880597, F1: 0.8208955223880597
Precision: 0.9701492537313433, Recall: 0.9701492537313433, F1: 0.9701492537313433
Precision: 0.9154228855721394, Recall: 0.9154228855721394, F1: 0.9154228855721394
Precision: 0.8955223880597015, Recall: 0.8955223880597015, F1: 0.8955223880597015
Precision: 0.9203980099502488, Recall: 0.9203980099502488, F1: 0.9203980099502488
Precision: 0.9651741293532339, Recall: 0.9651741293532339, F1: 0.9651741293532339
Overall Precision: 0.8918918918918919, Recall: 0.6346153846153846, F1: 0.7415730337078652
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
c:\Users\Matt\AppData\Local\Programs\Python\Python310\lib\site-packages\accelerate\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead:
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
Random Precision: 0.20141948115516398, Recall: 0.5108628181253879, F1: 0.28892399508513256
Precision: 0.9253731343283582, Recall: 0.9253731343283582, F1: 0.9253731343283582
Precision: 0.900497512437811, Recall: 0.900497512437811, F1: 0.9004975124378111
Precision: 0.8208955223880597, Recall: 0.8208955223880597, F1: 0.8208955223880597
Precision: 0.9701492537313433, Recall: 0.9701492537313433, F1: 0.9701492537313433
Precision: 0.9154228855721394, Recall: 0.9154228855721394, F1: 0.9154228855721394
Precision: 0.8955223880597015, Recall: 0.8955223880597015, F1: 0.8955223880597015
Precision: 0.9203980099502488, Recall: 0.9203980099502488, F1: 0.9203980099502488
Precision: 0.9651741293532339, Recall: 0.9651741293532339, F1: 0.9651741293532339
Overall Precision: 0.8918918918918919, Recall: 0.6346153846153846, F1: 0.7415730337078652
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
c:\Users\Matt\AppData\Local\Programs\Python\Python310\lib\site-packages\accelerate\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead:
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
Random Precision: 0.20141948115516398, Recall: 0.5108628181253879, F1: 0.28892399508513256
Precision: 0.9253731343283582, Recall: 0.9253731343283582, F1: 0.9253731343283582
Precision: 0.900497512437811, Recall: 0.900497512437811, F1: 0.9004975124378111
Precision: 0.8208955223880597, Recall: 0.8208955223880597, F1: 0.8208955223880597
Precision: 0.9701492537313433, Recall: 0.9701492537313433, F1: 0.9701492537313433
Precision: 0.9154228855721394, Recall: 0.9154228855721394, F1: 0.9154228855721394
Precision: 0.8955223880597015, Recall: 0.8955223880597015, F1: 0.8955223880597015
Precision: 0.9203980099502488, Recall: 0.9203980099502488, F1: 0.9203980099502488
Precision: 0.9651741293532339, Recall: 0.9651741293532339, F1: 0.9651741293532339
Overall Precision: 0.8918918918918919, Recall: 0.6346153846153846, F1: 0.7415730337078652
Random Precision: 0.1979882237487733, Recall: 0.5009310986964618, F1: 0.28380516968524705
Precision: 0.9253731343283582, Recall: 0.9253731343283582, F1: 0.9253731343283582
Precision: 0.900497512437811, Recall: 0.900497512437811, F1: 0.9004975124378111
Precision: 0.8208955223880597, Recall: 0.8208955223880597, F1: 0.8208955223880597
Precision: 0.9701492537313433, Recall: 0.9701492537313433, F1: 0.9701492537313433
Precision: 0.9154228855721394, Recall: 0.9154228855721394, F1: 0.9154228855721394
Precision: 0.8955223880597015, Recall: 0.8955223880597015, F1: 0.8955223880597015
Precision: 0.9203980099502488, Recall: 0.9203980099502488, F1: 0.9203980099502488
Precision: 0.9651741293532339, Recall: 0.9651741293532339, F1: 0.9651741293532339
Overall Precision: 0.8918918918918919, Recall: 0.6346153846153846, F1: 0.7415730337078652
Random Precision: 0.2097462949007787, Recall: 0.5183116076970825, F1: 0.2986409155937053
Precision: 0.9253731343283582, Recall: 0.9253731343283582, F1: 0.9253731343283582
Precision: 0.900497512437811, Recall: 0.900497512437811, F1: 0.9004975124378111
Precision: 0.8208955223880597, Recall: 0.8208955223880597, F1: 0.8208955223880597
Precision: 0.9701492537313433, Recall: 0.9701492537313433, F1: 0.9701492537313433
Precision: 0.9154228855721394, Recall: 0.9154228855721394, F1: 0.9154228855721394
Precision: 0.8955223880597015, Recall: 0.8955223880597015, F1: 0.8955223880597015
Precision: 0.9203980099502488, Recall: 0.9203980099502488, F1: 0.9203980099502488
Precision: 0.9651741293532339, Recall: 0.9651741293532339, F1: 0.9651741293532339
Overall Precision: 0.8918918918918919, Recall: 0.6346153846153846, F1: 0.7415730337078652
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
c:\Users\Matt\AppData\Local\Programs\Python\Python310\lib\site-packages\accelerate\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead:
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
Random Precision: 0.20141948115516398, Recall: 0.5108628181253879, F1: 0.28892399508513256
Precision: 0.9253731343283582, Recall: 0.9253731343283582, F1: 0.9253731343283582
Precision: 0.900497512437811, Recall: 0.900497512437811, F1: 0.9004975124378111
Precision: 0.8208955223880597, Recall: 0.8208955223880597, F1: 0.8208955223880597
Precision: 0.9701492537313433, Recall: 0.9701492537313433, F1: 0.9701492537313433
Precision: 0.9154228855721394, Recall: 0.9154228855721394, F1: 0.9154228855721394
Precision: 0.8955223880597015, Recall: 0.8955223880597015, F1: 0.8955223880597015
Precision: 0.9203980099502488, Recall: 0.9203980099502488, F1: 0.9203980099502488
Precision: 0.9651741293532339, Recall: 0.9651741293532339, F1: 0.9651741293532339
Overall Precision: 0.8918918918918919, Recall: 0.6346153846153846, F1: 0.7415730337078652
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
c:\Users\Matt\AppData\Local\Programs\Python\Python310\lib\site-packages\accelerate\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead:
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
Random Precision: 0.20141948115516398, Recall: 0.5108628181253879, F1: 0.28892399508513256
Precision: 0.9253731343283582, Recall: 0.9253731343283582, F1: 0.9253731343283582
Precision: 0.900497512437811, Recall: 0.900497512437811, F1: 0.9004975124378111
Precision: 0.8208955223880597, Recall: 0.8208955223880597, F1: 0.8208955223880597
Precision: 0.9701492537313433, Recall: 0.9701492537313433, F1: 0.9701492537313433
Precision: 0.9154228855721394, Recall: 0.9154228855721394, F1: 0.9154228855721394
Precision: 0.8955223880597015, Recall: 0.8955223880597015, F1: 0.8955223880597015
Precision: 0.9203980099502488, Recall: 0.9203980099502488, F1: 0.9203980099502488
Precision: 0.9651741293532339, Recall: 0.9651741293532339, F1: 0.9651741293532339
Overall Precision: 0.8918918918918919, Recall: 0.6346153846153846, F1: 0.7415730337078652
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
c:\Users\Matt\AppData\Local\Programs\Python\Python310\lib\site-packages\accelerate\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead:
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
Random Precision: 0.20141948115516398, Recall: 0.5108628181253879, F1: 0.28892399508513256
Precision: 0.9253731343283582, Recall: 0.9253731343283582, F1: 0.9253731343283582
Precision: 0.900497512437811, Recall: 0.900497512437811, F1: 0.9004975124378111
Precision: 0.8208955223880597, Recall: 0.8208955223880597, F1: 0.8208955223880597
Precision: 0.9701492537313433, Recall: 0.9701492537313433, F1: 0.9701492537313433
Precision: 0.9154228855721394, Recall: 0.9154228855721394, F1: 0.9154228855721394
Precision: 0.8955223880597015, Recall: 0.8955223880597015, F1: 0.8955223880597015
Precision: 0.9203980099502488, Recall: 0.9203980099502488, F1: 0.9203980099502488
Precision: 0.9651741293532339, Recall: 0.9651741293532339, F1: 0.9651741293532339
Overall Precision: 0.8918918918918919, Recall: 0.6346153846153846, F1: 0.7415730337078652
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
c:\Users\Matt\AppData\Local\Programs\Python\Python310\lib\site-packages\accelerate\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead:
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
<class 'transformers.tokenization_utils_base.BatchEncoding'>
{'input_ids': [0, 713, 16, 10, 1296, 9, 5, 19233, 6315, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
Random Precision: 0.20141948115516398, Recall: 0.5108628181253879, F1: 0.28892399508513256
Precision: 0.9253731343283582, Recall: 0.9253731343283582, F1: 0.9253731343283582
Precision: 0.900497512437811, Recall: 0.900497512437811, F1: 0.9004975124378111
Precision: 0.8208955223880597, Recall: 0.8208955223880597, F1: 0.8208955223880597
Precision: 0.9701492537313433, Recall: 0.9701492537313433, F1: 0.9701492537313433
Precision: 0.9154228855721394, Recall: 0.9154228855721394, F1: 0.9154228855721394
Precision: 0.8955223880597015, Recall: 0.8955223880597015, F1: 0.8955223880597015
Precision: 0.9203980099502488, Recall: 0.9203980099502488, F1: 0.9203980099502488
Precision: 0.9651741293532339, Recall: 0.9651741293532339, F1: 0.9651741293532339
Overall Precision: 0.8918918918918919, Recall: 0.6346153846153846, F1: 0.7415730337078652
<class 'transformers.tokenization_utils_base.BatchEncoding'>
{'input_ids': [0, 713, 16, 10, 1296, 9, 5, 19233, 6315, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
c:\Users\Matt\AppData\Local\Programs\Python\Python310\lib\site-packages\accelerate\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead:
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
Random Precision: 0.20141948115516398, Recall: 0.5108628181253879, F1: 0.28892399508513256
Precision: 0.9253731343283582, Recall: 0.9253731343283582, F1: 0.9253731343283582
Precision: 0.900497512437811, Recall: 0.900497512437811, F1: 0.9004975124378111
Precision: 0.8208955223880597, Recall: 0.8208955223880597, F1: 0.8208955223880597
Precision: 0.9701492537313433, Recall: 0.9701492537313433, F1: 0.9701492537313433
Precision: 0.9154228855721394, Recall: 0.9154228855721394, F1: 0.9154228855721394
Precision: 0.8955223880597015, Recall: 0.8955223880597015, F1: 0.8955223880597015
Precision: 0.9203980099502488, Recall: 0.9203980099502488, F1: 0.9203980099502488
Precision: 0.9651741293532339, Recall: 0.9651741293532339, F1: 0.9651741293532339
Overall Precision: 0.8918918918918919, Recall: 0.6346153846153846, F1: 0.7415730337078652
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
c:\Users\Matt\AppData\Local\Programs\Python\Python310\lib\site-packages\accelerate\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead:
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
<class 'transformers.tokenization_utils_base.BatchEncoding'>
{'input_ids': [0, 713, 16, 10, 1296, 9, 5, 19233, 6315, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
Random Precision: 0.20141948115516398, Recall: 0.5108628181253879, F1: 0.28892399508513256
Precision: 0.9253731343283582, Recall: 0.9253731343283582, F1: 0.9253731343283582
Precision: 0.900497512437811, Recall: 0.900497512437811, F1: 0.9004975124378111
Precision: 0.8208955223880597, Recall: 0.8208955223880597, F1: 0.8208955223880597
Precision: 0.9701492537313433, Recall: 0.9701492537313433, F1: 0.9701492537313433
Precision: 0.9154228855721394, Recall: 0.9154228855721394, F1: 0.9154228855721394
Precision: 0.8955223880597015, Recall: 0.8955223880597015, F1: 0.8955223880597015
Precision: 0.9203980099502488, Recall: 0.9203980099502488, F1: 0.9203980099502488
Precision: 0.9651741293532339, Recall: 0.9651741293532339, F1: 0.9651741293532339
Overall Precision: 0.8918918918918919, Recall: 0.6346153846153846, F1: 0.7415730337078652
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
c:\Users\Matt\AppData\Local\Programs\Python\Python310\lib\site-packages\accelerate\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead:
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
<class 'transformers.tokenization_utils_base.BatchEncoding'>
{'input_ids': [0, 713, 16, 10, 1296, 9, 5, 19233, 6315, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
Random Precision: 0.20141948115516398, Recall: 0.5108628181253879, F1: 0.28892399508513256
Precision: 0.9253731343283582, Recall: 0.9253731343283582, F1: 0.9253731343283582
Precision: 0.900497512437811, Recall: 0.900497512437811, F1: 0.9004975124378111
Precision: 0.8208955223880597, Recall: 0.8208955223880597, F1: 0.8208955223880597
Precision: 0.9701492537313433, Recall: 0.9701492537313433, F1: 0.9701492537313433
Precision: 0.9154228855721394, Recall: 0.9154228855721394, F1: 0.9154228855721394
Precision: 0.8955223880597015, Recall: 0.8955223880597015, F1: 0.8955223880597015
Precision: 0.9203980099502488, Recall: 0.9203980099502488, F1: 0.9203980099502488
Precision: 0.9651741293532339, Recall: 0.9651741293532339, F1: 0.9651741293532339
Overall Precision: 0.8918918918918919, Recall: 0.6346153846153846, F1: 0.7415730337078652
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
c:\Users\Matt\AppData\Local\Programs\Python\Python310\lib\site-packages\accelerate\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead:
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
<class 'transformers.tokenization_utils_base.BatchEncoding'>
{'input_ids': [0, 713, 16, 10, 1296, 9, 5, 19233, 6315, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
Random Precision: 0.20141948115516398, Recall: 0.5108628181253879, F1: 0.28892399508513256
Precision: 0.9253731343283582, Recall: 0.9253731343283582, F1: 0.9253731343283582
Precision: 0.900497512437811, Recall: 0.900497512437811, F1: 0.9004975124378111
Precision: 0.8208955223880597, Recall: 0.8208955223880597, F1: 0.8208955223880597
Precision: 0.9701492537313433, Recall: 0.9701492537313433, F1: 0.9701492537313433
Precision: 0.9154228855721394, Recall: 0.9154228855721394, F1: 0.9154228855721394
Precision: 0.8955223880597015, Recall: 0.8955223880597015, F1: 0.8955223880597015
Precision: 0.9203980099502488, Recall: 0.9203980099502488, F1: 0.9203980099502488
Precision: 0.9651741293532339, Recall: 0.9651741293532339, F1: 0.9651741293532339
Overall Precision: 0.8918918918918919, Recall: 0.6346153846153846, F1: 0.7415730337078652
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
<class 'transformers.tokenization_utils_base.BatchEncoding'>
{'input_ids': [0, 713, 16, 10, 1296, 9, 5, 19233, 6315, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
c:\Users\Matt\AppData\Local\Programs\Python\Python310\lib\site-packages\accelerate\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead:
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
c:\Users\Matt\AppData\Local\Programs\Python\Python310\lib\site-packages\accelerate\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead:
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
c:\Users\Matt\AppData\Local\Programs\Python\Python310\lib\site-packages\accelerate\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead:
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
Random Precision: 0.1994501374656336, Recall: 0.49534450651769085, F1: 0.2843905915894512
Precision: 0.9253731343283582, Recall: 0.9253731343283582, F1: 0.9253731343283582
Precision: 0.900497512437811, Recall: 0.900497512437811, F1: 0.9004975124378111
Precision: 0.8208955223880597, Recall: 0.8208955223880597, F1: 0.8208955223880597
Precision: 0.9701492537313433, Recall: 0.9701492537313433, F1: 0.9701492537313433
Precision: 0.9154228855721394, Recall: 0.9154228855721394, F1: 0.9154228855721394
Precision: 0.8955223880597015, Recall: 0.8955223880597015, F1: 0.8955223880597015
Precision: 0.9203980099502488, Recall: 0.9203980099502488, F1: 0.9203980099502488
Precision: 0.9651741293532339, Recall: 0.9651741293532339, F1: 0.9651741293532339
Overall Precision: 0.8918918918918919, Recall: 0.6346153846153846, F1: 0.7415730337078652
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
c:\Users\Matt\AppData\Local\Programs\Python\Python310\lib\site-packages\accelerate\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead:
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
<class 'transformers.tokenization_utils_base.BatchEncoding'>
{'input_ids': [0, 713, 16, 10, 1296, 9, 5, 19233, 6315, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
Random Precision: 0.20141948115516398, Recall: 0.5108628181253879, F1: 0.28892399508513256
Precision: 0.9253731343283582, Recall: 0.9253731343283582, F1: 0.9253731343283582
Precision: 0.900497512437811, Recall: 0.900497512437811, F1: 0.9004975124378111
Precision: 0.8208955223880597, Recall: 0.8208955223880597, F1: 0.8208955223880597
Precision: 0.9701492537313433, Recall: 0.9701492537313433, F1: 0.9701492537313433
Precision: 0.9154228855721394, Recall: 0.9154228855721394, F1: 0.9154228855721394
Precision: 0.8955223880597015, Recall: 0.8955223880597015, F1: 0.8955223880597015
Precision: 0.9203980099502488, Recall: 0.9203980099502488, F1: 0.9203980099502488
Precision: 0.9651741293532339, Recall: 0.9651741293532339, F1: 0.9651741293532339
Overall Precision: 0.8918918918918919, Recall: 0.6346153846153846, F1: 0.7415730337078652
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
c:\Users\Matt\AppData\Local\Programs\Python\Python310\lib\site-packages\accelerate\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead:
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
