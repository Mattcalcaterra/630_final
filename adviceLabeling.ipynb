{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load base packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# load stats tools\n",
    "from scipy import stats\n",
    "\n",
    "# load dataset tools\n",
    "import datasets\n",
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "# preprocessing tools\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# load models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import torch\n",
    "from transformers import (\n",
    "    RobertaTokenizer,\n",
    "    RobertaForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "\n",
    "\n",
    "# load eval tools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# from transformers import EvalPrediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_df = pd.read_csv(\"data/AnnotatedData/AnnotatedDUGData.tsv\", sep=\"\\t\")\n",
    "load_shape = anno_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will drop the columns which we are not interested in\n",
    "anno_df = anno_df[\n",
    "    [\n",
    "        \"Drug number\",\n",
    "        \"Line number\",\n",
    "        \"Advice Text\",\n",
    "        \"AdviceTag1\",\n",
    "        \"AdviceTag2\",\n",
    "        \"AdviceTag3\",\n",
    "        \"AdviceTag4\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = (\n",
    "    anno_df[[\"AdviceTag1\", \"AdviceTag2\", \"AdviceTag3\", \"AdviceTag4\"]]\n",
    "    .fillna(\"\")\n",
    "    .astype(str)\n",
    ")\n",
    "\n",
    "label_ids = list(set(labels.values.flatten()))\n",
    "\n",
    "# remove the empty string\n",
    "label_ids.remove(\"\")\n",
    "\n",
    "\n",
    "n_label_ids = len(label_ids)\n",
    "n_label_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode advice labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Drug number</th>\n",
       "      <th>Line number</th>\n",
       "      <th>Advice Text</th>\n",
       "      <th>Pregnancy related</th>\n",
       "      <th>Activity or lifestyle related</th>\n",
       "      <th>Other drugs related</th>\n",
       "      <th>Exercise related</th>\n",
       "      <th>Drug administration related</th>\n",
       "      <th>Disease or symptom related</th>\n",
       "      <th>Food or beverage related</th>\n",
       "      <th>Temporal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>To reduce the risk of dizziness and lightheade...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>This medication may rarely make your blood sug...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>This medication may rarely cause a condition k...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>This drug may make you dizzy or drowsy or caus...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>Avoid alcoholic beverages.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Drug number  Line number  \\\n",
       "0            0           34   \n",
       "1            0           38   \n",
       "2            0           43   \n",
       "3            0           64   \n",
       "4            0           66   \n",
       "\n",
       "                                         Advice Text  Pregnancy related  \\\n",
       "0  To reduce the risk of dizziness and lightheade...                  0   \n",
       "1  This medication may rarely make your blood sug...                  0   \n",
       "2  This medication may rarely cause a condition k...                  0   \n",
       "3  This drug may make you dizzy or drowsy or caus...                  0   \n",
       "4                         Avoid alcoholic beverages.                  0   \n",
       "\n",
       "   Activity or lifestyle related  Other drugs related  Exercise related  \\\n",
       "0                              1                    0                 0   \n",
       "1                              0                    0                 0   \n",
       "2                              0                    0                 0   \n",
       "3                              1                    0                 0   \n",
       "4                              0                    0                 0   \n",
       "\n",
       "   Drug administration related  Disease or symptom related  \\\n",
       "0                            0                           0   \n",
       "1                            0                           1   \n",
       "2                            0                           1   \n",
       "3                            0                           1   \n",
       "4                            0                           0   \n",
       "\n",
       "   Food or beverage related  Temporal  \n",
       "0                         0         0  \n",
       "1                         0         0  \n",
       "2                         0         0  \n",
       "3                         0         0  \n",
       "4                         1         0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new columns for each unique tag and initialize them with 0\n",
    "for lab in label_ids:\n",
    "    anno_df[lab] = 0\n",
    "\n",
    "# Update the values to 1 where the tag is present\n",
    "for lab in label_ids:\n",
    "    mask = labels.apply(lambda row: lab in row.values, axis=1)\n",
    "    anno_df.loc[mask, lab] = 1\n",
    "\n",
    "# Drop the original AdviceTag columns\n",
    "anno_df.drop(\n",
    "    columns=[\"AdviceTag1\", \"AdviceTag2\", \"AdviceTag3\", \"AdviceTag4\"],\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# Save the transformed data to a new file\n",
    "anno_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensure the encoding was correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert anno_df.shape[0] == load_shape[0], \"Mismatch in number of rows\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two baselines will be tested with for the multilabel classification task.\n",
    "\n",
    "The  baseline will be a random baseline, where the labels are randomly assigned to the advice text.\n",
    "\n",
    "The baseline will be evaluated using the F1 score, Precision, and Recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_baseline_pred(dataset, n_labels=8):\n",
    "    \"\"\"\n",
    "    Randomly predicts a label for each example in the dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset (datasets.Dataset): The dataset to predict labels for.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The predicted labels.\n",
    "    \"\"\"\n",
    "\n",
    "    return np.random.randint(0, 2, size=(len(dataset), n_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data into dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_label = datasets.Dataset.from_pandas(anno_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify ground truth labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = anno_df[label_ids].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ground_truth.shape[0] == load_shape[0], \"Mismatch in number of rows\"\n",
    "assert ground_truth.shape[1] == n_label_ids, \"Mismatch in number of columns\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions and evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Precision: 0.19905566600397614, Recall: 0.4972067039106145, F1: 0.2842945874001775\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "rand_preds = rand_baseline_pred(multi_label)\n",
    "# print(rand_preds.shape)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "    ground_truth, rand_preds, average=\"micro\"\n",
    ")\n",
    "print(f\"Random Precision: {precision}, Recall: {recall}, F1: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Drug number', 'Line number', 'Advice Text', 'Pregnancy related',\n",
       "       'Activity or lifestyle related', 'Other drugs related',\n",
       "       'Exercise related', 'Drug administration related',\n",
       "       'Disease or symptom related', 'Food or beverage related', 'Temporal'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anno_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the unneeded columns\n",
    "anno_df.drop([\"Drug number\", \"Line number\"], axis=1, inplace=True)\n",
    "\n",
    "# Create train test split\n",
    "train, test = train_test_split(anno_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Relevance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For binary relevance we will encode the text using a TF-IDF vectorizer and then train a logistic regression model for each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Advice Text</th>\n",
       "      <th>Pregnancy related</th>\n",
       "      <th>Activity or lifestyle related</th>\n",
       "      <th>Other drugs related</th>\n",
       "      <th>Exercise related</th>\n",
       "      <th>Drug administration related</th>\n",
       "      <th>Disease or symptom related</th>\n",
       "      <th>Food or beverage related</th>\n",
       "      <th>Temporal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Some products that may interact with this drug...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Beta-blocker medications (such as metoprolol, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>Wash your hands after applying the patch.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>Lithium passes into breast milk and may have u...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>Limit alcoholic beverages.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Advice Text  Pregnancy related  \\\n",
       "78   Some products that may interact with this drug...                  0   \n",
       "29   Beta-blocker medications (such as metoprolol, ...                  0   \n",
       "280          Wash your hands after applying the patch.                  0   \n",
       "507  Lithium passes into breast milk and may have u...                  1   \n",
       "652                         Limit alcoholic beverages.                  0   \n",
       "\n",
       "     Activity or lifestyle related  Other drugs related  Exercise related  \\\n",
       "78                               0                    1                 0   \n",
       "29                               0                    1                 0   \n",
       "280                              1                    0                 0   \n",
       "507                              0                    0                 0   \n",
       "652                              0                    0                 0   \n",
       "\n",
       "     Drug administration related  Disease or symptom related  \\\n",
       "78                             0                           0   \n",
       "29                             0                           1   \n",
       "280                            1                           0   \n",
       "507                            0                           0   \n",
       "652                            0                           0   \n",
       "\n",
       "     Food or beverage related  Temporal  \n",
       "78                          0         0  \n",
       "29                          0         0  \n",
       "280                         0         0  \n",
       "507                         0         0  \n",
       "652                         1         0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at our data\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data encoding with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pregnancy related', 'Activity or lifestyle related',\n",
       "       'Other drugs related', 'Exercise related',\n",
       "       'Drug administration related', 'Disease or symptom related',\n",
       "       'Food or beverage related', 'Temporal'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# Fit and transform the train data\n",
    "X_train = vectorizer.fit_transform(train[\"Advice Text\"])\n",
    "\n",
    "# Transform the test data\n",
    "X_test = vectorizer.transform(test[\"Advice Text\"])\n",
    "\n",
    "label_ids = train.columns[1:]\n",
    "label_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = LogisticRegression(max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Pregnancy related\n",
      "Precision: 1.0, Recall: 0.8636363636363636, F1: 0.9268292682926829\n",
      "Training model for Activity or lifestyle related\n",
      "Precision: 1.0, Recall: 0.38461538461538464, F1: 0.5555555555555556\n",
      "Training model for Other drugs related\n",
      "Precision: 0.9310344827586207, Recall: 0.8307692307692308, F1: 0.8780487804878049\n",
      "Training model for Exercise related\n",
      "Precision: 0.0, Recall: 0.0, F1: 0.0\n",
      "Training model for Drug administration related\n",
      "Precision: 1.0, Recall: 0.5333333333333333, F1: 0.6956521739130436\n",
      "Training model for Disease or symptom related\n",
      "Precision: 0.6578947368421053, Recall: 0.5208333333333334, F1: 0.5813953488372092\n",
      "Training model for Food or beverage related\n",
      "Precision: 0.8787878787878788, Recall: 0.6904761904761905, F1: 0.7733333333333333\n",
      "Training model for Temporal\n",
      "Precision: 0.8571428571428571, Recall: 0.5142857142857142, F1: 0.6428571428571428\n",
      "\n",
      "Precision: 0.8918918918918919, Recall: 0.6346153846153846, F1: 0.7415730337078652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Matt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame()\n",
    "for label in label_ids:\n",
    "    print(f\"Training model for {label}\")\n",
    "    y_train = train[label]\n",
    "    y_test = test[label]\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the test data\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        y_test, preds, average=\"binary\"\n",
    "    )\n",
    "    print(f\"Precision: {precision}, Recall: {recall}, F1: {f1}\")\n",
    "\n",
    "    results[label] = preds\n",
    "\n",
    "# Evaluate the model\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "    test[label_ids], results, average=\"micro\"\n",
    ")\n",
    "print(f\"\\nPrecision: {precision}, Recall: {recall}, F1: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(train, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"roberta-base\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data into dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load into datasets\n",
    "train_dataset = datasets.Dataset.from_pandas(train, preserve_index=False)\n",
    "val_dataset = datasets.Dataset.from_pandas(val, preserve_index=False)\n",
    "test_dataset = datasets.Dataset.from_pandas(test, preserve_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename Advice Text to text\n",
    "train_dataset = train_dataset.rename_column(\"Advice Text\", \"text\")\n",
    "val_dataset = val_dataset.rename_column(\"Advice Text\", \"text\")\n",
    "test_dataset = test_dataset.rename_column(\"Advice Text\", \"text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize and split text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(batch):\n",
    "\n",
    "    text = batch[\"text\"]\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    labels = list(batch.keys())[1:]\n",
    "\n",
    "    label_array = np.zeros((len(text), len(labels)))\n",
    "\n",
    "    for i, label in enumerate(labels):\n",
    "        label_array[:, i] = batch[label]\n",
    "\n",
    "    inputs[\"labels\"] = label_array\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ce56233d6414e5d966e1d4f402b61df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/562 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7924e9ad1d0d44f69ea85cf44b9e3307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/242 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f5a69653cdc4aedbc4442ef795a8bfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/201 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_encodings = train_dataset.map(preprocess_text, batched=True)\n",
    "eval_encodings = val_dataset.map(preprocess_text, batched=True)\n",
    "test_encodings = test_dataset.map(preprocess_text, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format datasets\n",
    "train_encodings.set_format(\n",
    "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"]\n",
    ")\n",
    "eval_encodings.set_format(\n",
    "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"]\n",
    ")\n",
    "test_encodings.set_format(\n",
    "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([8])\n",
      "<s>If you are planning pregnancy, become pregnant, or think you may be pregnant, immediately discuss the benefits and risks of using this medication during pregnancy with your doctor.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
     ]
    }
   ],
   "source": [
    "# example\n",
    "example = train_encodings[0]\n",
    "print(example[\"input_ids\"].shape)\n",
    "print(example[\"attention_mask\"].shape)\n",
    "print(example[\"labels\"].shape)\n",
    "\n",
    "print(tokenizer.decode(example[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = anno_df.columns[1:].tolist()\n",
    "n_labels = len(class_names)\n",
    "\n",
    "id2label = {i: label for i, label in enumerate(class_names)}\n",
    "label2id = {label: i for i, label in enumerate(class_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics function\n",
    "def compute_metrics(eval_pred):\n",
    "    logits = eval_pred.predictions\n",
    "    labels = eval_pred.label_ids\n",
    "\n",
    "    probs = torch.sigmoid(torch.tensor(logits)).numpy()\n",
    "\n",
    "    preds = (probs > 0.5).astype(int)\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, preds, average=\"micro\"\n",
    "    )\n",
    "\n",
    "    return {\"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./models/roberta-base\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=25,\n",
    "    logging_dir=f\"./logs\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=10,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=500,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=25,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    save_total_limit=2,\n",
    "    report_to=\"wandb\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained(\n",
    "    model_id, num_labels=n_labels, id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Matt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\accelerate\\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_encodings,\n",
    "    eval_dataset=eval_encodings,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([562, 512])\n",
      "torch.Size([562, 512])\n",
      "torch.Size([562, 8])\n"
     ]
    }
   ],
   "source": [
    "# Check sizes\n",
    "print(train_encodings[\"input_ids\"].shape)\n",
    "print(train_encodings[\"attention_mask\"].shape)\n",
    "print(train_encodings[\"labels\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmattcalc\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Matt\\Documents\\GitHub\\630_final\\wandb\\run-20240421_105513-km85fkrf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mattcalc/huggingface/runs/km85fkrf' target=\"_blank\">hardy-puddle-47</a></strong> to <a href='https://wandb.ai/mattcalc/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mattcalc/huggingface' target=\"_blank\">https://wandb.ai/mattcalc/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mattcalc/huggingface/runs/km85fkrf' target=\"_blank\">https://wandb.ai/mattcalc/huggingface/runs/km85fkrf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "329389f075bf4a2194e80957a7e1b91c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/213 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6846, 'grad_norm': 1.3883836269378662, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.14}\n",
      "{'loss': 0.6829, 'grad_norm': 1.6674448251724243, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.28}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c16193016cf7482fb5227d0af50ee43e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6701627373695374, 'eval_precision': 0.20523415977961432, 'eval_recall': 0.3941798941798942, 'eval_f1': 0.26992753623188404, 'eval_runtime': 4.9216, 'eval_samples_per_second': 49.171, 'eval_steps_per_second': 6.299, 'epoch': 0.35}\n",
      "{'loss': 0.6681, 'grad_norm': 1.191691517829895, 'learning_rate': 3e-06, 'epoch': 0.42}\n",
      "{'loss': 0.661, 'grad_norm': 1.1009907722473145, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.56}\n",
      "{'loss': 0.6363, 'grad_norm': 1.2419812679290771, 'learning_rate': 5e-06, 'epoch': 0.7}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72e8e6b70d3245f4b0a5e2678cc78c7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6281105875968933, 'eval_precision': 0.3140877598152425, 'eval_recall': 0.35978835978835977, 'eval_f1': 0.3353884093711467, 'eval_runtime': 4.9141, 'eval_samples_per_second': 49.246, 'eval_steps_per_second': 6.308, 'epoch': 0.7}\n",
      "{'loss': 0.6049, 'grad_norm': 1.9708466529846191, 'learning_rate': 6e-06, 'epoch': 0.85}\n",
      "{'loss': 0.5459, 'grad_norm': 1.6542376279830933, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7332e34067494f1696e5102204542cf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Matt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4808005392551422, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_runtime': 4.649, 'eval_samples_per_second': 52.054, 'eval_steps_per_second': 6.668, 'epoch': 1.06}\n",
      "{'loss': 0.5156, 'grad_norm': 1.9831092357635498, 'learning_rate': 8.000000000000001e-06, 'epoch': 1.13}\n",
      "{'loss': 0.4845, 'grad_norm': 1.5671510696411133, 'learning_rate': 9e-06, 'epoch': 1.27}\n",
      "{'loss': 0.4471, 'grad_norm': 1.721231460571289, 'learning_rate': 1e-05, 'epoch': 1.41}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "833e0fcc42ee417085b791b558ee1a62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4091169536113739, 'eval_precision': 1.0, 'eval_recall': 0.07407407407407407, 'eval_f1': 0.13793103448275862, 'eval_runtime': 4.635, 'eval_samples_per_second': 52.211, 'eval_steps_per_second': 6.688, 'epoch': 1.41}\n",
      "{'loss': 0.4266, 'grad_norm': 1.5391569137573242, 'learning_rate': 1.1000000000000001e-05, 'epoch': 1.55}\n",
      "{'loss': 0.3706, 'grad_norm': 1.6853445768356323, 'learning_rate': 1.2e-05, 'epoch': 1.69}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0baf49dfc1e347b4b5b3d907aa9da0cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3198750913143158, 'eval_precision': 0.9196787148594378, 'eval_recall': 0.6058201058201058, 'eval_f1': 0.730462519936204, 'eval_runtime': 16.8603, 'eval_samples_per_second': 14.353, 'eval_steps_per_second': 1.839, 'epoch': 1.76}\n",
      "{'loss': 0.3524, 'grad_norm': 2.5425198078155518, 'learning_rate': 1.3000000000000001e-05, 'epoch': 1.83}\n",
      "{'loss': 0.337, 'grad_norm': 1.972846269607544, 'learning_rate': 1.4000000000000001e-05, 'epoch': 1.97}\n",
      "{'loss': 0.2931, 'grad_norm': 2.1307029724121094, 'learning_rate': 1.5e-05, 'epoch': 2.11}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bfb6740c6b74a978b06f6b163c54a64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2645148038864136, 'eval_precision': 0.9180887372013652, 'eval_recall': 0.7116402116402116, 'eval_f1': 0.8017883755588673, 'eval_runtime': 4.8484, 'eval_samples_per_second': 49.913, 'eval_steps_per_second': 6.394, 'epoch': 2.11}\n",
      "{'loss': 0.2637, 'grad_norm': 1.6760720014572144, 'learning_rate': 1.6000000000000003e-05, 'epoch': 2.25}\n",
      "{'loss': 0.2464, 'grad_norm': 1.8481371402740479, 'learning_rate': 1.7000000000000003e-05, 'epoch': 2.39}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f410ffac9c6d4f6da44d21a9c48b6e6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2209036648273468, 'eval_precision': 0.9403973509933775, 'eval_recall': 0.7513227513227513, 'eval_f1': 0.8352941176470587, 'eval_runtime': 4.979, 'eval_samples_per_second': 48.604, 'eval_steps_per_second': 6.226, 'epoch': 2.46}\n",
      "{'loss': 0.2397, 'grad_norm': 2.067387342453003, 'learning_rate': 1.8e-05, 'epoch': 2.54}\n",
      "{'loss': 0.2258, 'grad_norm': 2.2678611278533936, 'learning_rate': 1.9e-05, 'epoch': 2.68}\n",
      "{'loss': 0.2132, 'grad_norm': 1.1475797891616821, 'learning_rate': 2e-05, 'epoch': 2.82}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0eda65a87484dc5928a415b5cab33d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.19929257035255432, 'eval_precision': 0.8944281524926686, 'eval_recall': 0.8068783068783069, 'eval_f1': 0.8484005563282336, 'eval_runtime': 4.936, 'eval_samples_per_second': 49.028, 'eval_steps_per_second': 6.28, 'epoch': 2.82}\n",
      "{'loss': 0.2159, 'grad_norm': 1.2862308025360107, 'learning_rate': 2.1e-05, 'epoch': 2.96}\n",
      "{'train_runtime': 170.321, 'train_samples_per_second': 9.899, 'train_steps_per_second': 1.251, 'train_loss': 0.4308803666365538, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=213, training_loss=0.4308803666365538, metrics={'train_runtime': 170.321, 'train_samples_per_second': 9.899, 'train_steps_per_second': 1.251, 'train_loss': 0.4308803666365538, 'epoch': 3.0})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d07629ff55394aab9a08237e57fe7eb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.19929257035255432,\n",
       " 'eval_precision': 0.8944281524926686,\n",
       " 'eval_recall': 0.8068783068783069,\n",
       " 'eval_f1': 0.8484005563282336,\n",
       " 'eval_runtime': 4.8202,\n",
       " 'eval_samples_per_second': 50.205,\n",
       " 'eval_steps_per_second': 6.431,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40e0fba6d2ea405aacda05b0a8b908e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.8962962962962963, 'recall': 0.7756410256410257, 'f1': 0.831615120274914}\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "test_results = trainer.predict(test_encodings)\n",
    "\n",
    "test_metrics = compute_metrics(test_results)\n",
    "print(test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting new text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
